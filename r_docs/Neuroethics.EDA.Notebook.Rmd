---
title: "R Notebook"
output: html_notebook
---

Kiante Fernandez

#Main Hypotheses

1) Consistent with previous research on behavioral economics and moral decision making, we hypothesize that participants will be more psychologically risk averse to harm than gain motivated.

2) Participants risk aversion to harm will change as the cognitive domain being treated changes. Specifically, participants will be more risk averse to mood, and self-control because these are more central to self-identity.

3) Participants who are more affluent, educated, liberal, and younger will be risk seeking relative to the average risky decision making behavior observed when judging treatments for others.

- note: we need income, age, education, and political affli here. 

4) In a classification model, the proportion of benefit to harm ratio will be more predictive of whether someone chooses an experimental treatment than the benefits or risks alone. 

##Set the stage
```{r load libraries }
#this will load the libraries and WILL INSTALL IF YOU DO NOT HAVE THE PACKAGE (heads up)
packages <- c('readr','dplyr','tidyselect','magrittr','ggplot2','ggpubr','reshape2', 'stringr')
if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
  install.packages(setdiff(packages, rownames(installed.packages())))
}
lapply(packages, library, character.only = TRUE)

rm(list=ls())
```

```{r Import and Transform task data, message=FALSE, warning=FALSE, include=FALSE}
#note to pull data in terminal: aws s3 sync s3://neuroethics-task .
files <- list.files(path = "../data/mturk_data/mturk_data_05162020", pattern = "*.csv", full.names = T)

#combine all the task csv into a list

pilot <- sapply(files, readr::read_csv, simplify=FALSE) 
Mpilot = bind_rows(pilot)

N = 75#Set the min number of trials

#get needed variables from from pulled csv for each subject
cleanPilot = select_(Mpilot,
                     "user_id",
                     "condition",
                     "total_trials",
                     "risk",
                     "gain",
                     "no_effect", 
                     "experimental_treatment_selected", 
                     "key_press", 
                     "rt")
cleanPilot = na.omit(cleanPilot) 
cleanPilot = filter(cleanPilot, total_trials >= N)
cleanPilot = mutate(cleanPilot, ratio = gain / risk)#Gain over Risk

cleanPilot$condition = factor(cleanPilot$condition)
```

```{r remove specific pilot users}
#this removes the subjects task data that we collected on an accidently deployment
REMOVE = c(
  "wpchz8fz",
  "tdDTyNLl",
  "CUyB01Th",
  "d9UbV0sj",
  "PiGCo5DO",
  "yCZDIVJF",
  "WUTFOue2",
  "Rp8H93tM",
  "9Z5vJ7oT",
  "esSkjqdS",
  "XNHqndg3",
  "spGR9XvT",
  "qf27dbHj",
  "y6m1AOsD",
  "hgbHHiLn",
  "Ly8mJkxP"
)

for (i in REMOVE){
cleanPilot <- cleanPilot %>% 
  filter(!str_detect(user_id, i))
}
```


###Add Survey Data 

```{r survey data integration}
#survey = read.csv("../data/Qualtrics Data/Final_Pilot_survey.csv", header=TRUE, comment.char="#", stringsAsFactors=TRUE)

survey = read.csv("../data/Qualtrics Data/May_16_2020.csv", header=TRUE, comment.char="#", stringsAsFactors=TRUE)
survey <- filter(survey, batch >= 3) #498
```

```{r careless/insufficient effort responce check}
#Remove Duplicates
Double.REMOVE = read.csv("../data/Redundancies.csv", header=TRUE, comment.char="#", stringsAsFactors=TRUE)

for (i in Double.REMOVE$Completion_Code){
  survey <- survey %>% 
    filter(!str_detect(ResponseId, i))
}

#Attention checks
survey = filter(survey, attention_check.1 == 1)
survey = filter(survey, attention_check.2 == 1)
survey = filter(survey, attention_check.3 == 1)
survey = filter(survey, attention_check.4 == 1)

#Time to complete survey
library(psych)
time2completion <- cbind(survey$Duration..in.seconds./60, survey[18])

survey = survey[,-c(1:17)]
#self report data quality check

Self.Report <- cbind(survey[,"user_id"], survey[,189:195])

colnames(Self.Report) <- c('user_id',
                           'accurate',
                           'without.reading',
                           'rushed', 
                           'include.data',
                           'randomly',
                           'effort',
                           'careful.thought')
  
Remove.1 <- Self.Report %>% #Remove by self reported randomness apprasial
  filter(randomly >=5)

Remove.2 <- Self.Report %>%  #Remove by self reported subjective data quality 
  filter(!randomly >=5) %>%
  filter(include.data <=3)

Remove.3 <- Self.Report %>%  #Remove by self reported rushing
  filter(!randomly >=5) %>%
  filter(!include.data <=3) %>%
  filter(rushed >=5)

Remove <- rbind(Remove.1,Remove.2,Remove.3)

for (i in Remove$user_id){
survey <- survey %>% 
  filter(!str_detect(user_id, i))
}

rm(Remove.1,Remove.2,Remove.3)

##Time to complete survey
for (i in Remove$user_id){
time2completion <- time2completion %>% 
  filter(!str_detect(user_id, i))
}
survey <- merge(survey, time2completion, "user_id")
colnames(survey)[199] <- "time2completion"

survey = filter(survey, time2completion >= 7)
#303
```

```{r Personlity Big 5}
Big5 <- cbind(survey[,38:97], survey[1])

for (i in 1:60) {
  Big5[[i]] <- as.numeric(Big5[[i]])
}

Big5List = list(
  Extraversion <-  
    Big5[, c(1, 6, 11, 16, 21, 26, 31, 36, 41, 46, 51, 56)],
  Agreeableness <- 
    Big5[, c(2, 7, 12, 17, 22, 27, 32, 37, 42, 47, 52, 57)],
  Conscientiousness <-  
    Big5[, c(3, 8, 13, 18, 23, 28, 33, 38, 43, 48, 53, 58)],
  Negative_Emotionality <- 
    Big5[, c(4, 9, 14, 19, 24, 29, 34, 39, 44, 49, 54, 59)],
  Open_Mindedness <- 
    Big5[, c(5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60)])

Results = list()
for (i in 1:5){
  totals <- apply(Big5List[[i]], 1, sum)
  Results[[i]] = totals 
}
TEST = do.call(rbind, Results)
colnames(TEST) = survey[,"user_id"]
rownames(TEST) <- c('Extraversion','Agreeableness','Conscientiousness','Negative_Emotionality','Open_Mindedness')
TEST = as.data.frame(t(TEST))
XX <- cbind(user_id = Big5[,"user_id"], TEST)

cleanPilot = merge(cleanPilot, XX, "user_id")
rm(XX, TEST, Results,totals)
```

```{r Moral Foundations Survey}
MFQ <- cbind(survey[,4:36], survey[1])
MFQ <- MFQ[,-17]#take out attention check

MFQList <- list(
  Harm <- MFQ[,c(1,7,12,17,23,28)],
  Fairness <- MFQ[,c(2,8,13,18,24,29)],
  Loyalty <- MFQ[,c(3,9,14,19,25,30)],
  Athority <- MFQ[,c(4,10,15,20,26,31)],
  Sancticy <- MFQ[,c(5,11,16,21,27,32)])

Results = list()
for (i in 1:5){
  totals <- apply(MFQList[[i]], 1, sum)
  Results[[i]] = totals 
}

TEST = do.call(rbind, Results)
colnames(TEST) = survey[,"user_id"]
rownames(TEST) <- c('Harm','Fairness','Loyalty','Athority','Sancticy')
TEST <-  as.data.frame(t(TEST))
XX <- cbind(user_id = MFQ[,"user_id"], TEST)

cleanPilot <-  merge(cleanPilot, XX, "user_id")
```

```{r Empathy-IRI; Interpersonal Reactivity Index}
IRI <- cbind(survey[,139:167], survey[1])
IRI <- IRI[,-24]#take out attention check

IRIList <- list(
  PerspectiveTaking <- IRI[,c("PT1","PT2","PT3","PT4","PT5","PT6","PT7")],
  Fantasy <- IRI[,c("FS1","FS2","FS3","FS4","FS5","FS6","FS7")],
  EmpathicConcern <- IRI[,c("EC1","EC2","EC3","EC4","EC5","EC6","EC7")],
  PersonalDistress <- IRI[,c("PD1","PD2","PD3","PD4","PD5","PD6","PD7")]
)

Results = list()
for (i in 1:4){
  totals <- apply(IRIList[[i]], 1, sum)
  Results[[i]] = totals 
}

TEST = do.call(rbind, Results)
colnames(TEST) = survey[,"user_id"]
rownames(TEST) <- c('PerspectiveTaking', 'Fantasy', 'EmpathicConcern','PersonalDistress')
TEST <-  as.data.frame(t(TEST))
XX <- cbind(user_id = IRI[,"user_id"], TEST)

cleanPilot <-  merge(cleanPilot, XX, "user_id")
```

```{r Short Schwartzs Value Survey}
SVS <- cbind(survey[,122:132], survey[1])
SVS <- SVS[,-7]#take out attention check

SVSList <- list(
  POWER <- SVS[,1],
  ACHIEVEMENT <- SVS[,2],
  HEDONISM <- SVS[,3],
  STIMULATION <- SVS[,4],
  SELF.DIRECTION <- SVS[,5],
  UNIVERSALISM <- SVS[,6],
  BENEVOLENCE <- SVS[,7],
  TRADITION <- SVS[,8],
  CONFORMITY <- SVS[,9],
  SECURITY<- SVS[,10]
)

TEST = do.call(rbind, SVSList)
colnames(TEST) = survey[,"user_id"]
rownames(TEST) <- c('POWER','ACHIEVEMENT','HEDONISM','STIMULATION','SELF.DIRECTION', 'UNIVERSALISM','BENEVOLENCE','TRADITION','CONFORMITY','SECURITY')
TEST <-  as.data.frame(t(TEST))
XX <- cbind(user_id = SVS[,"user_id"], TEST)

cleanPilot <-  merge(cleanPilot, XX, "user_id")
```

```{r Lombrozo Moral Commitments task}
#need to fix how is scored
MC <- cbind(survey[,133:138], survey[1])

Results = list()
for (i in 1:6){
  totals <- apply(MC[i],1,sum)
  Results[[i]] = totals 
}

TEST = do.call(rbind, Results)
colnames(TEST) = survey[,"user_id"]
rownames(TEST) <- c('Lying','Assasination','Torture','Murder','Stealing','ForcedSterilization')
TEST <-  as.data.frame(t(TEST))
XX <- cbind(user_id = MC[,"user_id"], TEST)

cleanPilot <-  merge(cleanPilot, XX, "user_id")
```

```{r Subjective Numeracy Scale (SNS)}
SNS <- cbind(survey[,168:175], survey[1])

SNSList <- list(
  SNS.total <- SNS[,c(1,2,3,4,5,6,7,8)],
  SNS.ability <- SNS[,c(1,2,3,4)],
  SNS.preference <- SNS[,c(5,6,7,8)]
)

Results = list()
for (i in 1:3){
  totals <- apply(SNSList[[i]], 1, mean)
  Results[[i]] = totals 
}

TEST = do.call(rbind, Results)
colnames(TEST) = survey[,"user_id"]
rownames(TEST) <- c('SNS.total','SNS.ability','SNS.preference')
TEST <-  as.data.frame(t(TEST))
XX <- cbind(user_id = SNS[,"user_id"], TEST)

cleanPilot <-  merge(cleanPilot, XX, "user_id")
```

```{r Berlin Numeracy Test}
Berlin.Numeracy.Test<- cbind(survey[, 176:179], survey[1])
```

```{r GRiPs}
GRiPs <- cbind(survey[,180:187], survey[1])

GRiPsList <- list(
  GRiPs.score <- GRiPs[,c(1,2,3,4,5,6,7,8)])

Results = list()
totals <- apply(GRiPsList[[1]], 1, sum)
Results[[1]] = totals 

TEST = do.call(rbind, Results)
colnames(TEST) = survey[,"user_id"]
rownames(TEST) <- c('GRiPs.score')
TEST <-  as.data.frame(t(TEST))
XX <- cbind(user_id = GRiPs[,"user_id"], TEST)

cleanPilot <-  merge(cleanPilot, XX, "user_id")
```

```{r Political Orientation}
Political.Orientation <-  cbind(survey[, 117:121], survey[1])
cleanPilot <-  merge(cleanPilot, Political.Orientation, "user_id")
```

```{r Demographics}
Demographics <-  cbind(survey[, 98:116], survey[1])
Demographics$sex <- as.factor(Demographics$sex) 
cleanPilot <-  merge(cleanPilot, Demographics, "user_id")

cleanPilot$education <- factor(cleanPilot$education,  
                       labels = c("less than high school",
                                  "high school degree", 
                                  "bachelor", 
                                  "masters", 
                                  "Doctoral/Professional"),
                       levels = c(1,2,3,4,5))

cleanPilot$sex <- factor(cleanPilot$sex,  
                       labels = c("Male", 
                                  "Female", 
                                  "Other"),
                       levels = c(1,2,3))

cleanPilot$race_ethnicity <- factor(cleanPilot$race_ethnicity,
                             labels = c("Black", 
                                        "White", 
                                        "Hispanic or Latino",
                                        "Asian",
                                        "Native Hawaiian/Pacific Islander",
                                        "American Indian/Alaska Native",
                                        "Mixed",
                                        "Other",
                                        "Prefer not to say"),
                             levels = c(1,2,3,4,5,6,7,8,9))

cleanPilot$Political_Party <- factor(cleanPilot$Political_Party,  
                       labels = c("Democrat", 
                                  "Republican", 
                                  "Independent",
                                  "Other"),
                       levels = c(1,2,3,4))

cleanPilot$RelationshipStatus <- factor(cleanPilot$RelationshipStatus,  
                       labels = c("Single", 
                                  "In a Relationship", 
                                  "Married",
                                  "Widowed",
                                  "Divorced",
                                  "Other"),
                       levels = c(1,2,3,4,5,6))

cleanPilot$ReligionRaised <- factor(cleanPilot$ReligionRaised,  
                       labels = c("Christianity", 
                                  "Judaism", 
                                  "Islam",
                                  "Unitarian Universal",
                                  "Buddhism",
                                  "Hinduism",
                                  "Agnosticism", 
                                  "Athesism", 
                                  "Humanism",
                                  "Paganism",
                                  "None",
                                  "Other"),
                       levels = c(1,2,3,4,5,6,7,8,9,10,11,12))

cleanPilot$ReligionNow <- factor(cleanPilot$ReligionNow,  
                       labels = c("Christianity", 
                                  "Judaism", 
                                  "Islam",
                                  "Unitarian Universal",
                                  "Buddhism",
                                  "Hinduism",
                                  "Agnosticism", 
                                  "Athesism", 
                                  "Humanism",
                                  "Paganism",
                                  "None",
                                  "Other"),
                       levels = c(1,2,3,4,5,6,7,8,9,10,11,12))
```

Check the RT data to see if we can ID any cases that are out of what we would expect. 
We expect people to respond no faster than 250ms

```{r RT data,}
#Check the RT data for outliers
n= nrow(cleanPilot)/75
trial_index = data_frame(rep.int(c(1:75), n)) 
colnames(trial_index)= c("trial_index")

cleanPilot = cbind(cleanPilot,trial_index)
cleanPilot$trial_index = factor(cleanPilot$trial_index)

cleanPilot = filter(cleanPilot, rt <= 60000 & rt >= 250)

cleanPilot =subset(cleanPilot, with(cleanPilot, user_id %in% names(which(table(user_id)>=N)))) #Remove Subjects who do not have 75 trials
#258
```

```{r plot RT}
#table(cleanPilot$user_id) Sanity Check
cleanPilot$user_id = factor(cleanPilot$user_id)
RT = select_(cleanPilot,"user_id", "rt", "trial_index")
summary(RT)
##Plots for RT 
data_long = melt(RT, 
                 id=c("user_id","trial_index"),
                 measure=c("rt"))

summary(data_long)

ggplot(data_long, aes(trial_index, value)) +
  stat_summary(fun = mean, geom = "line") +
  stat_summary(fun.data=mean_se, geom = "pointrange") +
  scale_y_continuous("RT (milliseconds)") +
  theme(axis.text.x = element_text(angle=65, vjust=0.6)) +
  labs(title="", 
       subtitle="",
       caption="",
       x="Trial Number",
       y="RT (milliseconds)")

datalist = list()
for (i in RT$user_id){
  x = filter(RT, user_id == i)
  dat = summary(x$rt) 
  datalist[[i]] = dat # add it to your list
}

user_id = factor(names(datalist)) #creates vector of user_id's 

for (i in user_id){
  x = filter(RT, user_id == i)
  sum = summary(x)
  print(sum)
  }

rm(data_long, x, datalist, trial_index)

```

```{r merging cleaned survey and task data}

Neuroethics_Judgement = cleanPilot
Neuroethics_Judgement$experimental_treatment_selected = factor(Neuroethics_Judgement$experimental_treatment_selected, labels = c("No to treatment","Yes to treatment"))

#write.csv(Neuroethics_Judgement,paste("../data/",'Cleaned_Pilot.07.csv',sep = ""))
```

```{r observation count}
#How many observatoins does each subject have in each class (yes and no)?
datalist = list()
for (i in Neuroethics_Judgement$user_id){
  x = filter(Neuroethics_Judgement, user_id == i)
  dat = table(x$experimental_treatment_selected) #Check Class bias
  datalist[[i]] = dat # add it to your list
}
Observation_Counts = do.call(rbind, datalist)
colnames(Observation_Counts) = c('No', 'Yes')
summary(Observation_Counts)
View(Observation_Counts)
rm(i, x,datalist, dat)
```

```{r Individual subject visual data check, eval=FALSE, include=FALSE}
#Mutiple Plots
source("../r_docs/Multiple_plot_function.R")

#Individual Scatter: subject graph 
for (i in user_id){
  sub = filter(Neuroethics_Judgement, user_id == i)
  
g = ggplot(sub,aes(x = risk , y = gain)) + 
  geom_point(aes(color = experimental_treatment_selected), size = 2.5, alpha = .7, position = "jitter") +
  ggtitle(paste("75 Trials Pilot Subject: ",toString(i))) +
  scale_x_continuous("Risk Probabilities", breaks=seq(0,100,5), limits=c(0, 100)) +
  scale_y_continuous("Gain Probabilities", breaks=seq(0,100,5), limits=c(0, 100)) + 
  theme(legend.position="none")
  
  png(filename = paste0(i , ".png"),
      width = 500, height = 372)
  print(g)
  dev.off()
}
for (i in user_id){
  sub = filter(Neuroethics_Judgement, user_id == i)
##Density Plots for risk, gain, and no effect
  p1 = ggdensity(sub, 
          main = paste("subject: ",toString(i)),
          x = "risk",
          legend.title = "",
          xticks.by = 10,
          add = "mean", rug = TRUE,
          color = "experimental_treatment_selected", 
          fill ="experimental_treatment_selected", 
          palette = c("#f8766d", "#00bfc4"))
  p3 = ggdensity(sub, 
          x = "gain",
          legend = "none",
          xticks.by = 10,
          add = "mean", rug = TRUE,
          color = "experimental_treatment_selected", 
          fill ="experimental_treatment_selected", 
          palette = c("#f8766d", "#00bfc4"))
  p5 = ggdensity(sub, 
          x = "no_effect",
          legend = "none",
          xticks.by = 10,
          add = "mean", rug = TRUE,
          color = "experimental_treatment_selected", 
          fill ="experimental_treatment_selected", 
          palette = c("#f8766d", "#00bfc4"))
##Histograms for risk, gain, and no effect
  p2=gghistogram(sub, 
            x = "risk",
            ylab = "Number of Occurrences",
            add = "mean", rug = TRUE,
            fill = "experimental_treatment_selected",  palette = c("#f8766d", "#00bfc4"),
            add_density = TRUE, bins = 30,
            legend = "none",
            xticks.by = 10)
  p4=gghistogram(sub, 
            x = "gain",
            ylab = "Number of Occurrences",
            add = "mean", rug = TRUE,
            fill = "experimental_treatment_selected",  palette = c("#f8766d", "#00bfc4"),
            add_density = TRUE, bins = 30,
            legend = "none",
            xticks.by = 10)
  p6=gghistogram(sub, 
            x = "no_effect",
            alpha = .5,
            ylab = "Number of Occurrences",
            add = "mean", rug = TRUE,
            fill = "experimental_treatment_selected",  palette = c("#f8766d", "#00bfc4"),
            add_density = TRUE, bins = 30, 
            legend = "none",
            xticks.by = 10)

  png(filename = paste0(i , ".png"),
    width = 1234, height = 468)
  multiplot(p1, p2, p3, p4, p5, p6, cols=3)
  dev.off()
}

 png(filename = paste0(i , ".png"),
    width = 1234, height = 468)
  multiplot(p2, p4, p6, cols=3)
  dev.off()
#Ratio plots
for (i in user_id){
  sub = filter(Neuroethics_Judgement, user_id == i)
  
##Density plot  
  p1 = ggdensity(sub, 
               x = "ratio",
               legend.title = paste("75 Trials Pilot Subject: ",toString(i)),
               add = "mean", rug = TRUE,
               color = "experimental_treatment_selected", 
               fill ="experimental_treatment_selected", 
               palette = c("#f8766d", "#00bfc4"),
               xticks.by = 1)
##Histogram
  p2 = gghistogram(sub, 
            x = "ratio",
            alpha = .5,
            ylab = "Number of Occurrences",
            add = "mean", rug = TRUE,
            fill = "experimental_treatment_selected",  palette = c("#f8766d", "#00bfc4"),
            add_density = TRUE, bins = 200,
            legend = "none", 
            xticks.by = 1)
  
  png(filename = paste0(i , ".png"),
    width = 1234, height = 468)
  multiplot(p1, p2, cols=1)
  dev.off()
}
```

##H1
Consistent with previous research on behavioral economics and moral decision making, we hypothesize that participants will be more psychologically risk averse to harm than gain motivated.

To do so, we will fit a binary logistic regression on the task data to display the subject wise sensitivity to risk of harm above and beyond that gain motivated judgments.  

The outcome (response) variable is binary (0/1); No treatment or Yes to experimental treatment. The predictor variables of interest are the amount of risk, gain, and no_effect within each trial. 

So we are modeling the probablity of the response from know values our prdictors(log-transformed).

```{r logisitic Regression}
####Logsistic Reg
#center_scale <- function(x) {
#    scale(x, scale = FALSE)
#}

#this only takes the mean
#Neuroethics_Judgement <- group_by(Neuroethics_Judgement, user_id) %>% 
#    mutate(risk_c= center_scale(risk)) %>% 
#    mutate(gain_c= center_scale(gain))

#this standardizes the scores
Neuroethics_Judgement <- group_by(Neuroethics_Judgement, user_id) %>% 
   mutate(risk_c= scale(risk)) %>% 
   mutate(gain_c= scale(gain))


subjectModel.1 = by(Neuroethics_Judgement, Neuroethics_Judgement$user_id, function(x) glm(experimental_treatment_selected ~ risk_c+ gain_c, data = x, family = binomial(link = "logit"),control=glm.control(maxit=50)))


subjectModel.2 = by(Neuroethics_Judgement, Neuroethics_Judgement$user_id, function(x) glm(experimental_treatment_selected ~ risk_c*gain_c, data = x, family = binomial(link = "logit"),control=glm.control(maxit=50)))

```


```{r Model comparisons}

user_id = names(subjectModel.1) #creates vector of user_id's 
n= nrow(Neuroethics_Judgement)/75

#loop an anove test of the interaction on base and ratio model
datalist = list()
for (i in 1:n){
dat = anova(subjectModel.1[[i]],
            subjectModel.2[[i]],
            test="Chisq")
  datalist[[i]] = dat
}
names(datalist) = user_id

lapply(datalist, print) 
lapply(subjectModel.3, summary)

```

```{r Pseduo R^2s }
source("../r_docs/logisticPseudoR2s.R")

#loop the r^2 calculator on the fitted final model
datalist.1 = list()
for (i in 1:n){
dat = logisticPseudoR2s(subjectModel.2[[i]])
  datalist.1[[i]] = dat
}
#subjectModel.R2 <-  do.call(rbind, datalist.1)
```

```{r odds ratios}
user_id = names(subjectModel.2) #creates vector of user_id's 
n = nrow(Neuroethics_Judgement)/75

#Compute odds ratio
datalist.2 = list()
for (i in 1:n){
dat = subjectModel.2[[i]]$coefficients
  datalist.2[[i]] = dat
}
subjectModel.OddRatios = do.call(rbind, datalist.2)

colnames(subjectModel.OddRatios) <-  c('Intercept', 'Risk_Beta', 'Gain_Beta', 'Interaction_Beta')

subjectModel.OddRatios <- cbind.data.frame(subjectModel.OddRatios, user_id)

Neuroethics_Judgement= merge(Neuroethics_Judgement, subjectModel.OddRatios, "user_id")
```


```{r pvalue extraction}
user_id = names(subjectModel.2) #creates vector of user_id's 
n= nrow(Neuroethics_Judgement)/75
#we want to pull out the models and give them a logical model signficant or not
datalist.pvalue = list()
for (i in user_id){
dat = coef(summary(subjectModel.2[[i]]))[,4]#This is coef pvalues
  datalist.pvalue[[i]] = dat
}
subjectModel.Pvalue <-t(bind_rows(datalist.pvalue))

colnames(subjectModel.Pvalue) <-  c('Intercept_sig', 'Risk_sig', 'Gain_sig', 'Interaction_sig')

for (ii in 1:4){
  for(jj in 1:n){
    if (subjectModel.Pvalue[jj,ii] > 0.05)
    subjectModel.Pvalue[jj,ii] <- 0
    else 
      subjectModel.Pvalue[jj,ii] <- 1
  }
}

subjectModel.Pvalue <- cbind.data.frame(user_id, subjectModel.Pvalue[,2:4])


Neuroethics_Judgement= merge(Neuroethics_Judgement, subjectModel.Pvalue, "user_id")
```


```{r Model Dignostics for best fitted model}
#Diagnostics for model 2 (Residuals)
#Interpreting residuaLs

datalist.dignostics = list()
for (i in user_id){
  subjectDignostics = filter(Neuroethics_Judgement, user_id == i)
    for (ii in 1:n){
      subjectDignostics$predicted.probabilities<-fitted(subjectModel.2[[ii]])
      subjectDignostics$standardized.residuals<-rstandard(subjectModel.2[[ii]])
      subjectDignostics$studentized.residuals<-rstudent(subjectModel.2[[ii]])
      subjectDignostics$dfbeta<-dfbeta(subjectModel.2[[ii]])
      subjectDignostics$dffit<-dffits(subjectModel.2[[ii]])
      subjectDignostics$leverage<-hatvalues(subjectModel.2[[ii]])}
  datalist.dignostics[[i]] = subjectDignostics
}

datalist.dignostics = do.call(rbind, datalist.dignostics)

#Neuroethics_Judgement = merge(Neuroethics_Judgement,datalist.dignostics, "user_id")
summary(datalist.dignostics)
```

```{r plot the fitted models for each subject, eval=FALSE, include=FALSE}
#Mutiple Plots
source("../r_docs/Multiple_plot_function.R")

for (i in user_id){
  subject = filter(datalist.dignostics, user_id == i)

  ggplot(subject, aes(x=risk, y= predicted.probabilities)) + 
      stat_summary(fun = mean, geom = "line")+
         scale_x_continuous(expand = c(0,0))
  
  ggplot(subject, aes(x=gain, y= predicted.probabilities)) + 
      stat_summary(fun = mean, geom = "line")+
         scale_x_continuous(expand = c(0,0))
  
    p1 = ggplot(subject, aes(x=risk, y= predicted.probabilities)) + 
         geom_point(size = 4, alpha = .5,   position = "jitter") + 
         stat_smooth(method="glm", se=FALSE, fullrange=TRUE, 
              method.args = list(family=quasibinomial))+
         scale_x_continuous(expand = c(0,0))+
         theme(legend.position="none")

    p2 = ggplot(subject, aes(x=gain, y= predicted.probabilities)) + 
         geom_point(size = 4, alpha = .5, position = "jitter") +
         stat_smooth(method="glm", se=FALSE, fullrange=TRUE, 
              method.args = list(family=quasibinomial))+
         scale_x_continuous(expand = c(0,0))+
         theme(legend.position="none")

    p3 = ggplot(subject,aes(x = risk , y = gain)) + 
         geom_point(aes(color = experimental_treatment_selected), 
                    size = 2.5, alpha = .7, position = "jitter") +
         ggtitle(paste("75 Trials Pilot Subject: ",toString(i))) +
         scale_x_continuous("Risk Probabilities",
                            breaks=seq(0,100,5), limits=c(0, 100)) +
         scale_y_continuous("Gain Probabilities", breaks=seq(0,100,5), 
                            limits=c(0, 100)) + 
         theme(legend.position="none")

     png(filename = paste0(i , ".png"),
       width = 1234, height = 468)
     multiplot(p1, p2, p3, cols=2)
     dev.off()
}

```

```{r beta check up}

coefficients = lapply(subjectModel.2, coef)
coefficients = do.call(rbind, coefficients)
coefficients = coefficients[,-1]#Removes intercept
#coefficients = coefficients[,3]#Removes interaction
coefficients = data.frame(coefficients)
colnames(coefficients)= c('Risk_Beta', 'Gain_Beta', 'Interaction')
coefficients$user_id = names(subjectModel.2)

#coefficients = exp(coefficients)#exponetiated 
# A basic box with the conditions colored
dat <- melt(coefficients, 
                       id = c("user_id"),
                       variable.name = "cond", 
                       value.name = "Beta")

ggplot(dat, aes(x=cond, y=Beta, fill=cond)) + geom_boxplot()+
      scale_y_continuous(limits=c(-10, 20))

```


```{r loss aversion}
Neuroethics_Judgement = mutate(Neuroethics_Judgement, lambda = -Risk_Beta/Gain_Beta)


loss_aversion <- mutate(coefficients, lambda = -Risk_Beta/Gain_Beta)

ggplot(loss_aversion, aes(x=lambda)) +
    geom_histogram(binwidth=1, colour="black", fill="white") +
    geom_vline(aes(xintercept=mean(lambda, na.rm=T)),
               color="red", linetype="dashed", size=1)+
    scale_x_continuous("Lambda", breaks=seq(-20,20,1), limits=c(-20, 20))+
    scale_y_continuous("Number of Occurrences")
library(knitr)
kable((summary(loss_aversion[5])), caption = "summary of lambda calculation")
```


```{r significant count plot}
dat.2 = distinct(select(Neuroethics_Judgement, user_id , condition, sex, age, education, Risk_sig, Gain_sig, Interaction_sig))

dat.2$user_id <- as.factor(dat.2$user_id)
dat.2$education <- as.factor(dat.2$education)

data_long.2 = melt(dat.2, 
            id = c("user_id", "condition", "sex", "education", "age"),
                       variable.name = "type", 
                       value.name = "Stimulus")

#Significant plots
ggplot(data_long.2, aes(x = type, fill = as.factor(Stimulus))) +
         geom_bar(color = 'black', stat="count", position = "dodge")+
         theme_classic()
```

##H2

Participants risk aversion to harm will change as the cognitive domain being treated changes. Specifically, participants will be more risk averse to mood, and self-control because these are more central to self-identity.

```{r multilevel model at the level of the group, fig.height=7, fig.width=12, dpi=300}
dat.1 = distinct(select(Neuroethics_Judgement, user_id , condition ,  Risk_Beta , Gain_Beta , Interaction_Beta, sex, age, education, trial_index))


dat.1 = melt(dat.1, 
            id = c("user_id", "condition", "sex", "education", "age", "trial_index"),
                       variable.name = "type", 
                       value.name = "Stimulus")


#dat.1$type <- relevel(dat.1$type, "")
library(lme4)
library(lmerTest)
#scale the continuous variables
dat.1$Stimulus_c <- scale(dat.1$Stimulus)
dat.1$age_c <- scale(dat.1$age)
dat.1$trial_index <- as.numeric(dat.1$trial_index)
dat.1$trial_index_c <- scale(dat.1$trial_index)


m.base <- lmer(Stimulus_c ~ trial_index_c +
                      (1 | condition), 
                      data = dat.1,REML=F)

m.0 <- lmer(Stimulus_c ~ trial_index_c + condition +
                      (1 | condition), 
                      data = dat.1,REML=F)

m.1 <- lmer(Stimulus_c ~ trial_index_c + condition + age_c +
                      (1 | condition), 
                      data = dat.1,REML=F)

m.2 <- lmer(Stimulus_c ~ trial_index_c + condition + age_c + sex +
                      (1 | condition), 
                      data = dat.1,REML=F)

m.3 <- lmer(Stimulus_c ~ trial_index_c + condition + age_c + sex + education +
                      (1 | condition), 
                      data = dat.1,REML=F)

m.4 <- lmer(Stimulus_c ~ trial_index_c*condition + age_c + sex + education +
                      (1 | condition), 
                      data = dat.1,REML=F)


anova(m.base, m.0, m.1, m.2, m.3, m.4)


plot(m.0, condition ~ resid(.), abline = 0 ) # generate diagnostic plots

plot(m.0, resid(., type = "pearson") ~ fitted(.) | condition, id = 0.05, 
     adj = -0.3, pch = 20, col = "gray40")

library(car)
# check homogeneity
leveneTest(dat.1$Stimulus, dat.1$condition, center = mean)

plot(m.0, pch = 20, col = "black", lty = "dotted")

plot(m.0, form = resid(., type = "pearson") ~ fitted(.) | condition, abline = 0, 
     cex = .5, pch = 20, col = "black")

# observed responses versus the within-group fitted values
plot(m.0, Stimulus ~ fitted(.), id = 0.05, adj = -0.3, cex = .8, pch = 20, col = "blue")
``` 


```{r manuscript plot drafts, eval=FALSE, include=FALSE}
#Draft of Main Box Plot Across conditions


ggplot(dat.1, aes(condition, y=Stimulus, fill=type)) +
  geom_boxplot()+
  scale_y_continuous("Beta", breaks=seq(-2, 2,.5), limits=c(-2, 2)) +
  theme(axis.text.x = element_text(angle=65, vjust=0.6)) +
  labs(title="", 
       subtitle="an investigation of domain differences",
       x="Cognitive Domian",
       y="Beta") +
       geom_smooth(method = "lm")

#Separate Box Plots across conditions
ggplot(dat.1, aes(condition, y=Stimulus, fill=type)) +
  geom_boxplot()+
  facet_wrap(~condition, scale="free")
```

##Testing stuff

```{r Density plots of beta per cog domain, eval=FALSE, include=FALSE}
#Density Plot for Risk, Gain,  Ratio
p1 = ggplot(TEST, aes(Risk_Beta)) +
  geom_density(aes(fill=factor(condition)), alpha=0.8) +
  scale_x_continuous("Beta", breaks=seq(-5,10,1), limits=c(-5, 10))+
  theme(axis.text.x = element_text(angle=65, vjust=0.6))


p2 = ggplot(TEST, aes(Gain_Beta)) +
  geom_density(aes(fill=factor(condition)), alpha=0.8) +
  scale_x_continuous("Beta", breaks=seq(-5,10,1), limits=c(-5, 10))+
  theme(axis.text.x = element_text(angle=65, vjust=0.6))
```

```{r mixed effect models drafts}
library(reshape2)
library(lme4)
library(lmerTest)
feee <- Neuroethics_Judgement

center_scale <- function(x) {
    scale(x, scale = FALSE)
}
multilevel.data <- dplyr::select(feee, user_id, condition, risk, gain, experimental_treatment_selected, trial_index, age_4, sex)

multilevel.data$user_id <- as.factor(multilevel.data$user_id)
multilevel.data$trial_index.c <- center_scale(as.numeric(multilevel.data$trial_index))
multilevel.data$age.c <- center_scale(multilevel.data$age_4)
multilevel.data$risk.c <- center_scale(multilevel.data$risk)
multilevel.data$gain.c <- center_scale(multilevel.data$gain)


m.base <- glmer(experimental_treatment_selected ~ 1 + (1 + trial_index | condition),
               data = multilevel.data, family = binomial,
               control=glmerControl(optimizer="bobyqa"))

m.1 <- glmer(experimental_treatment_selected ~ 1 + trial_index*risk.c*gain.c + age.c + (1 + trial_index| condition), data = multilevel.data, family = binomial, 
               control=glmerControl(optimizer="bobyqa"), nAGQ = 10)


ggplot(multilevel.data, aes(risk, experimental_treatment_selected, color = condition, shape = user_id))+ 
  
  
  stat_summary(fun.data=mean_se, geom="pointrange") +
   stat_summary(fun=mean, geom="line", linetype = 2) +
   labs(x="risk", y="Chosen experimental treatment") +
   theme_bw()+theme(legend.position="none")




library(gridExtra)

grid.arrange(p1,p2,ncol=2)
```

```{r Testing multicollinearity, eval=FALSE, include=FALSE}
library(car)

vif(subjectModel.2)
1/vif(subjectModel.2)

cor(subject[, c("risk", "gain", "no_effect")])

cor.test(subject$risk, subject$gain)  
cor.test(subject$risk, subject$no_effect)  
cor.test(subject$gain, subject$no_effect)
```

```{r Testing the linearity of the logit, eval=FALSE, include=FALSE}

#Create the interaction of Risk with log(risk)
subject$logRisk<-log(subject$risk)*subject$risk

#Create the interaction of Gain and No Effect with their logs

subject$logGain<-log(subject$gain)*subject$gain
subject$logNo_effect<-log(subject$no_effect)*subject$no_effect

head(subject)



subjectTest.1 <- glm(experimental_treatment_selected ~ 
                       risk +
                       gain + 
                       no_effect +
                       logRisk +
                       logGain +	
                       logNo_effect, 
                     data=subject, family=binomial())
summary(subjectTest.1)
# None of the Interaction variables show significance, so linearity test passes
```

```{r users to remove}
REMOVE = c(
  "wpchz8fz",
  "tdDTyNLl",
  "CUyB01Th",
  "d9UbV0sj",
  "PiGCo5DO",
  "yCZDIVJF",
  "WUTFOue2",
  "Rp8H93tM",
  "9Z5vJ7oT",
  "esSkjqdS",
  "XNHqndg3",
  "spGR9XvT",
  "qf27dbHj",
  "y6m1AOsD",
  "hgbHHiLn",
  "Ly8mJkxP"
)

Neuroethics_Judgement %>%
      group_by(user_id)  %>%
      mutate(Neuroethics_Judgement, risk_c= risk-mean(risk)) %>%
      mutate(Neuroethics_Judgement, gain_c= gain-mean(gain))

Neuroethics_Judgement %>%
      group_by(user_id)  %>%
      mutate(risk_c= risk-mean(risk)) %>%
      mutate(gain_c= gain-mean(gain))
```

```{r odds ratio confidence intervals, eval=FALSE, include=FALSE}
#Compute odds ratio confidence interval
#only works if values do not contain infinites...
datalist.3 = list()
for (i in 1:n){
dat = exp(confint(subjectModel.2[[i]]))
  datalist.3[[i]] = dat
}
```

```{r}

for (i in user_id){
  subject = filter(datalist.dignostics, user_id == i)

 p1 <-  ggplot(subject, aes(x=risk, y= standardized.residuals)) + 
          geom_point(position = 'jitter')+
          stat_smooth(method="glm", se=FALSE, fullrange=TRUE, 
              method.args = list(family=quasibinomial))+
          scale_x_continuous(expand = c(0,0))+
          scale_y_continuous("Mean Responce (0 = No 1 = Yes)",breaks=seq(0,1,0.25), 
                            limits=c(0, 1))
  
  p2 <- ggplot(subject, aes(x=gain, y= predicted.probabilities)) + 
           stat_summary(fun = mean, geom = "line")+
          
           scale_x_continuous(expand = c(0,0))+
          scale_y_continuous("Mean Responce (0 = No 1 = Yes)",breaks=seq(0,1,0.25), 
                            limits=c(0, 1))  
   png(filename = paste0(i , ".png"),
       width = 1234, height = 468)
     multiplot(p1, p2, cols=2)
     dev.off()
}
```