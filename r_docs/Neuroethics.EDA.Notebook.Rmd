---
title: "R Notebook"
output: html_notebook
---

Kiante Fernandez

#Main Hypotheses

1) Consistent with previous research on behavioral economics and moral decision making, we hypothesize that participants will be more psychologically risk averse to harm than gain motivated.

2) Participants risk aversion to harm will change as the cognitive domain being treated changes. Specifically, participants will be more risk averse to mood, and self-control because these are more central to self-identity.

3) Participants who are more affluent, educated, liberal, and younger will be risk seeking relative to the average risky decision making behavior observed when judging treatments for others.

- note: we need income, age, education, and political affli here. 

4) In a classification model, the proportion of benefit to harm ratio will be more predictive of whether someone chooses an experimental treatment than the benefits or risks alone. 

##Set the stage
```{r load libraries }
packages <- c('readr','dplyr','tidyselect','magrittr','ggplot2','ggpubr','reshape2')
if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
  install.packages(setdiff(packages, rownames(installed.packages())))
}
lapply(packages, library, character.only = TRUE)

rm(list=ls())

```

```{r Import and Transform task data, message=FALSE, warning=FALSE, include=FALSE}
#note to pull data in terminal: aws s3 sync s3://neuroethics-task .
files <- list.files(path = "../data/mturk_data_05102020", pattern = "*.csv", full.names = T)

pilot <- sapply(files, readr::read_csv, simplify=FALSE) 
Mpilot = bind_rows(pilot)

N = 75#Set the min number of trials
cleanPilot = select_(Mpilot,
                     "user_id",
                     "condition",
                     "total_trials",
                     "risk",
                     "gain",
                     "no_effect", 
                     "experimental_treatment_selected", 
                     "key_press", 
                     "rt")
cleanPilot = na.omit(cleanPilot) 
cleanPilot = filter(cleanPilot, total_trials >= N)
cleanPilot = mutate(cleanPilot, ratio = gain / risk)#Gain over Risk

cleanPilot$condition = factor(cleanPilot$condition)

#write.csv(Neuroethics_Judgement,'Cleaned_Pilot.01.csv')
```

```{r remove specific pilot users}
library(stringr)

REMOVE = c(
  "wpchz8fz",
  "tdDTyNLl",
  "CUyB01Th",
  "d9UbV0sj",
  "PiGCo5DO",
  "yCZDIVJF",
  "WUTFOue2",
  "Rp8H93tM",
  "9Z5vJ7oT",
  "esSkjqdS",
  "XNHqndg3",
  "spGR9XvT",
  "qf27dbHj",
  "y6m1AOsD",
  "hgbHHiLn",
  "Ly8mJkxP"
)

for (i in REMOVE){
cleanPilot <- cleanPilot %>% 
  filter(!str_detect(user_id, i))
}
```


###Add Survey Data 

```{r survey data integration}
#survey = read.csv("../data/Qualtrics Data/Final_Pilot_survey.csv", header=TRUE, comment.char="#", stringsAsFactors=TRUE)

#survey.1 = read.csv("../data/Qualtrics Data/Qualtrics_5_04.csv", header=TRUE, comment.char="#", stringsAsFactors=TRUE)

survey = read.csv("../data/Qualtrics Data/May_10_2020.csv", header=TRUE, comment.char="#", stringsAsFactors=TRUE) %>% 
  filter(batch == 1)

batch.1 <- filter(survey, batch == 1)
batch.2 <- filter(survey, batch == 2)

batch.70.1 <- filter(survey, batch == 3)
batch.70.2 <- filter(survey, batch == 4)

```

```{r careless/insufficient effort responce check}
#Attention checks
survey = filter(survey, attention_check.1 == 1)
survey = filter(survey, attention_check.2 == 1)
survey = filter(survey, attention_check.3 == 1)
survey = filter(survey, attention_check.4 == 1)

#Time to complete survey
library(psych)
time2completion <- cbind(survey$Duration..in.seconds./60, survey[18])

survey = survey[,-c(1:17)]
#self report data quality check

Self.Report <- cbind(survey[,"user_id"], survey[,189:195])

colnames(Self.Report) <- c('user_id', 'accurate','without.reading','rushed', 'include.data','randomly','effort','careful.thought')
  
Remove.1 <- Self.Report %>% #Remove by self reported randomness apprasial
  filter(randomly >=5)

Remove.2 <- Self.Report %>%  #Remove by self reported subjective data quality 
  filter(!randomly >=5) %>%
  filter(include.data <=3)

Remove.3 <- Self.Report %>%  #Remove by self reported rushing
  filter(!randomly >=5) %>%
  filter(!include.data <=3) %>%
  filter(rushed >=5)

Remove <- rbind(Remove.1,Remove.2,Remove.3)

for (i in Remove$user_id){
survey <- survey %>% 
  filter(!str_detect(user_id, i))
}

rm(Remove.1,Remove.2,Remove.3)

##Time to complete survey
for (i in Remove$user_id){
time2completion <- time2completion %>% 
  filter(!str_detect(user_id, i))
}
survey <- merge(survey, time2completion, "user_id")
colnames(survey)[199] <- "time2completion"

survey = filter(survey, time2completion >= 7)

batch <- cbind(survey[1],survey[198])
cleanPilot <- merge(cleanPilot, batch, "user_id")
```

```{r Personlity Big 5}
Big5 <- cbind(survey[,38:97], survey[1])

for (i in 1:60) {
  Big5[[i]] <- as.numeric(Big5[[i]])
}

Big5List = list(
  Extraversion <-  
    Big5[, c(1, 6, 11, 16, 21, 26, 31, 36, 41, 46, 51, 56)],
  Agreeableness <- 
    Big5[, c(2, 7, 12, 17, 22, 27, 32, 37, 42, 47, 52, 57)],
  Conscientiousness <-  
    Big5[, c(3, 8, 13, 18, 23, 28, 33, 38, 43, 48, 53, 58)],
  Negative_Emotionality <- 
    Big5[, c(4, 9, 14, 19, 24, 29, 34, 39, 44, 49, 54, 59)],
  Open_Mindedness <- 
    Big5[, c(5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60)])

Results = list()
for (i in 1:5){
  totals <- apply(Big5List[[i]], 1, sum)
  Results[[i]] = totals 
}
TEST = do.call(rbind, Results)
colnames(TEST) = survey[,"user_id"]
rownames(TEST) <- c('Extraversion','Agreeableness','Conscientiousness','Negative_Emotionality','Open_Mindedness')
TEST = as.data.frame(t(TEST))
XX <- cbind(user_id = Big5[,"user_id"], TEST)

cleanPilot = merge(cleanPilot, XX, "user_id")
rm(XX, TEST, Results,totals)
```

```{r Moral Foundations Survey}
MFQ <- cbind(survey[,4:36], survey[1])
MFQ <- MFQ[,-17]#take out attention check

MFQList <- list(
  Harm <- MFQ[,c(1,7,12,17,23,28)],
  Fairness <- MFQ[,c(2,8,13,18,24,29)],
  Loyalty <- MFQ[,c(3,9,14,19,25,30)],
  Athority <- MFQ[,c(4,10,15,20,26,31)],
  Sancticy <- MFQ[,c(5,11,16,21,27,32)])

Results = list()
for (i in 1:5){
  totals <- apply(MFQList[[i]], 1, sum)
  Results[[i]] = totals 
}

TEST = do.call(rbind, Results)
colnames(TEST) = survey[,"user_id"]
rownames(TEST) <- c('Harm','Fairness','Loyalty','Athority','Sancticy')
TEST <-  as.data.frame(t(TEST))
XX <- cbind(user_id = MFQ[,"user_id"], TEST)

cleanPilot <-  merge(cleanPilot, XX, "user_id")
```

```{r Empathy-IRI; Interpersonal Reactivity Index}
IRI <- cbind(survey[,139:167], survey[1])
IRI <- IRI[,-24]#take out attention check

IRIList <- list(
  PerspectiveTaking <- IRI[,c("PT1","PT2","PT3","PT4","PT5","PT6","PT7")],
  Fantasy <- IRI[,c("FS1","FS2","FS3","FS4","FS5","FS6","FS7")],
  EmpathicConcern <- IRI[,c("EC1","EC2","EC3","EC4","EC5","EC6","EC7")],
  PersonalDistress <- IRI[,c("PD1","PD2","PD3","PD4","PD5","PD6","PD7")]
)

Results = list()
for (i in 1:4){
  totals <- apply(IRIList[[i]], 1, sum)
  Results[[i]] = totals 
}

TEST = do.call(rbind, Results)
colnames(TEST) = survey[,"user_id"]
rownames(TEST) <- c('PerspectiveTaking', 'Fantasy', 'EmpathicConcern','PersonalDistress')
TEST <-  as.data.frame(t(TEST))
XX <- cbind(user_id = IRI[,"user_id"], TEST)

cleanPilot <-  merge(cleanPilot, XX, "user_id")
```

```{r Short Schwartzs Value Survey}
SVS <- cbind(survey[,122:132], survey[1])
SVS <- SVS[,-7]#take out attention check

SVSList <- list(
  POWER <- SVS[,1],
  ACHIEVEMENT <- SVS[,2],
  HEDONISM <- SVS[,3],
  STIMULATION <- SVS[,4],
  SELF.DIRECTION <- SVS[,5],
  UNIVERSALISM <- SVS[,6],
  BENEVOLENCE <- SVS[,7],
  TRADITION <- SVS[,8],
  CONFORMITY <- SVS[,9],
  SECURITY<- SVS[,10]
)

TEST = do.call(rbind, SVSList)
colnames(TEST) = survey[,"user_id"]
rownames(TEST) <- c('POWER','ACHIEVEMENT','HEDONISM','STIMULATION','SELF.DIRECTION', 'UNIVERSALISM','BENEVOLENCE','TRADITION','CONFORMITY','SECURITY')
TEST <-  as.data.frame(t(TEST))
XX <- cbind(user_id = SVS[,"user_id"], TEST)

cleanPilot <-  merge(cleanPilot, XX, "user_id")
```

```{r Lombrozo Moral Commitments task}
#need to fix how is scored
MC <- cbind(survey[,133:138], survey[1])

Results = list()
for (i in 1:6){
  totals <- apply(MC[i],1,sum)
  Results[[i]] = totals 
}

TEST = do.call(rbind, Results)
colnames(TEST) = survey[,"user_id"]
rownames(TEST) <- c('Lying','Assasination','Torture','Murder','Stealing','ForcedSterilization')
TEST <-  as.data.frame(t(TEST))
XX <- cbind(user_id = MC[,"user_id"], TEST)

cleanPilot <-  merge(cleanPilot, XX, "user_id")
```

```{r Subjective Numeracy Scale (SNS)}
SNS <- cbind(survey[,168:175], survey[1])

SNSList <- list(
  SNS.total <- SNS[,c(1,2,3,4,5,6,7,8)],
  SNS.ability <- SNS[,c(1,2,3,4)],
  SNS.preference <- SNS[,c(5,6,7,8)]
)

Results = list()
for (i in 1:3){
  totals <- apply(SNSList[[i]], 1, mean)
  Results[[i]] = totals 
}

TEST = do.call(rbind, Results)
colnames(TEST) = survey[,"user_id"]
rownames(TEST) <- c('SNS.total','SNS.ability','SNS.preference')
TEST <-  as.data.frame(t(TEST))
XX <- cbind(user_id = SNS[,"user_id"], TEST)

cleanPilot <-  merge(cleanPilot, XX, "user_id")
```

```{r Berlin Numeracy Test}
Berlin.Numeracy.Test<- cbind(survey[, 176:179], survey[1])
```

```{r GRiPs}
GRiPs <- cbind(survey[,180:187], survey[1])

GRiPsList <- list(
  GRiPs.score <- GRiPs[,c(1,2,3,4,5,6,7,8)])

Results = list()
totals <- apply(GRiPsList[[1]], 1, sum)
Results[[1]] = totals 

TEST = do.call(rbind, Results)
colnames(TEST) = survey[,"user_id"]
rownames(TEST) <- c('GRiPs.score')
TEST <-  as.data.frame(t(TEST))
XX <- cbind(user_id = GRiPs[,"user_id"], TEST)

cleanPilot <-  merge(cleanPilot, XX, "user_id")
```

```{r Political Orientation}
Political.Orientation <-  cbind(survey[, 117:121], survey[1])
cleanPilot <-  merge(cleanPilot, Political.Orientation, "user_id")
```

```{r Demographics}
Demographics <-  cbind(survey[, 98:116], survey[1])
Demographics$sex <- as.factor(Demographics$sex) 
cleanPilot <-  merge(cleanPilot, Demographics, "user_id")
```

Check the RT data to see if we can ID any cases that are out of what we would expect. 
We expect people to respond no faster than 250ms

```{r RT data,}
#Check the RT data for outliers
n= nrow(cleanPilot)/75
trial_index = data_frame(rep.int(c(1:75), n)) 
colnames(trial_index)= c("trial_index")

cleanPilot = cbind(cleanPilot,trial_index)
cleanPilot$trial_index = factor(cleanPilot$trial_index)

cleanPilot = filter(cleanPilot, rt <= 60000 & rt >= 250)

cleanPilot =subset(cleanPilot, with(cleanPilot, user_id %in% names(which(table(user_id)>=N)))) #Remove Subjects who do not have 75 trials
```

```{r plot RT}
#table(cleanPilot$user_id) Sanity Check
cleanPilot$user_id = factor(cleanPilot$user_id)
RT = select_(cleanPilot,"user_id", "rt", "trial_index")
summary(RT)
##Plots for RT 
data_long = melt(RT, 
                 id=c("user_id","trial_index"),
                 measure=c("rt"))

summary(data_long)

ggplot(data_long, aes(trial_index, value)) +
  stat_summary(fun = mean, geom = "line") +
  stat_summary(fun.data=mean_se, geom = "pointrange") +
  scale_y_continuous("RT (milliseconds)") +
  theme(axis.text.x = element_text(angle=65, vjust=0.6)) +
  labs(title="", 
       subtitle="",
       caption="",
       x="Trial Number",
       y="RT (milliseconds)")

datalist = list()
for (i in RT$user_id){
  x = filter(RT, user_id == i)
  dat = summary(x$rt) 
  datalist[[i]] = dat # add it to your list
}

user_id = factor(names(datalist)) #creates vector of user_id's 

for (i in user_id){
  x = filter(RT, user_id == i)
  sum = summary(x)
  print(sum)
  }

rm(data_long, x, datalist, trial_index)

```



```{r merging cleaned survey and task data}

Neuroethics_Judgement = cleanPilot
Neuroethics_Judgement$experimental_treatment_selected = factor(Neuroethics_Judgement$experimental_treatment_selected, labels = c("No to treatment","Yes to treatment"))

#write.csv(Neuroethics_Judgement,paste("../data/",'batch.1.csv',sep = ""))

```


```{r observation count}
#How many observatoins does each subject have in each class (yes and no)?
datalist = list()
for (i in Neuroethics_Judgement$user_id){
  x = filter(Neuroethics_Judgement, user_id == i)
  dat = table(x$experimental_treatment_selected) #Check Class bias
  datalist[[i]] = dat # add it to your list
}
Observation_Counts = do.call(rbind, datalist)
colnames(Observation_Counts) = c('No', 'Yes')
summary(Observation_Counts)
View(Observation_Counts)
rm(i, x,datalist, dat)
```

```{r Individual subject visual data check, eval=FALSE, include=FALSE}
#Mutiple Plots
source("../r_docs/Multiple_plot_function.R")

#Individual Scatter: subject graph 
for (i in user_id){
  sub = filter(Neuroethics_Judgement, user_id == i)
  
g = ggplot(sub,aes(x = risk , y = gain)) + 
  geom_point(aes(color = experimental_treatment_selected), size = 2.5, alpha = .7, position = "jitter") +
  ggtitle(paste("75 Trials Pilot Subject: ",toString(i))) +
  scale_x_continuous("Risk Probabilities", breaks=seq(0,100,5), limits=c(0, 100)) +
  scale_y_continuous("Gain Probabilities", breaks=seq(0,100,5), limits=c(0, 100)) + 
  theme(legend.position="none")
  
  png(filename = paste0(i , ".png"),
      width = 500, height = 372)
  print(g)
  dev.off()
}
for (i in user_id){
  sub = filter(Neuroethics_Judgement, user_id == i)
##Density Plots for risk, gain, and no effect
  p1 = ggdensity(sub, 
          main = paste("subject: ",toString(i)),
          x = "risk",
          legend.title = "",
          xticks.by = 10,
          add = "mean", rug = TRUE,
          color = "experimental_treatment_selected", 
          fill ="experimental_treatment_selected", 
          palette = c("#f8766d", "#00bfc4"))
  p3 = ggdensity(sub, 
          x = "gain",
          legend = "none",
          xticks.by = 10,
          add = "mean", rug = TRUE,
          color = "experimental_treatment_selected", 
          fill ="experimental_treatment_selected", 
          palette = c("#f8766d", "#00bfc4"))
  p5 = ggdensity(sub, 
          x = "no_effect",
          legend = "none",
          xticks.by = 10,
          add = "mean", rug = TRUE,
          color = "experimental_treatment_selected", 
          fill ="experimental_treatment_selected", 
          palette = c("#f8766d", "#00bfc4"))
##Histograms for risk, gain, and no effect
  p2=gghistogram(sub, 
            x = "risk",
            ylab = "Number of Occurrences",
            add = "mean", rug = TRUE,
            fill = "experimental_treatment_selected",  palette = c("#f8766d", "#00bfc4"),
            add_density = TRUE, bins = 30,
            legend = "none",
            xticks.by = 10)
  p4=gghistogram(sub, 
            x = "gain",
            ylab = "Number of Occurrences",
            add = "mean", rug = TRUE,
            fill = "experimental_treatment_selected",  palette = c("#f8766d", "#00bfc4"),
            add_density = TRUE, bins = 30,
            legend = "none",
            xticks.by = 10)
  p6=gghistogram(sub, 
            x = "no_effect",
            alpha = .5,
            ylab = "Number of Occurrences",
            add = "mean", rug = TRUE,
            fill = "experimental_treatment_selected",  palette = c("#f8766d", "#00bfc4"),
            add_density = TRUE, bins = 30, 
            legend = "none",
            xticks.by = 10)

  png(filename = paste0(i , ".png"),
    width = 1234, height = 468)
  multiplot(p1, p2, p3, p4, p5, p6, cols=3)
  dev.off()
}

 png(filename = paste0(i , ".png"),
    width = 1234, height = 468)
  multiplot(p2, p4, p6, cols=3)
  dev.off()
#Ratio plots
for (i in user_id){
  sub = filter(Neuroethics_Judgement, user_id == i)
  
##Density plot  
  p1 = ggdensity(sub, 
               x = "ratio",
               legend.title = paste("75 Trials Pilot Subject: ",toString(i)),
               add = "mean", rug = TRUE,
               color = "experimental_treatment_selected", 
               fill ="experimental_treatment_selected", 
               palette = c("#f8766d", "#00bfc4"),
               xticks.by = 1)
##Histogram
  p2 = gghistogram(sub, 
            x = "ratio",
            alpha = .5,
            ylab = "Number of Occurrences",
            add = "mean", rug = TRUE,
            fill = "experimental_treatment_selected",  palette = c("#f8766d", "#00bfc4"),
            add_density = TRUE, bins = 200,
            legend = "none", 
            xticks.by = 1)
  
  png(filename = paste0(i , ".png"),
    width = 1234, height = 468)
  multiplot(p1, p2, cols=1)
  dev.off()
}
```

##H1
Consistent with previous research on behavioral economics and moral decision making, we hypothesize that participants will be more psychologically risk averse to harm than gain motivated.

To do so, we will fit a binary logistic regression on the task data to display the subject wise sensitivity to risk of harm above and beyond that gain motivated judgments.  

The outcome (response) variable is binary (0/1); No treatment or Yes to experimental treatment. The predictor variables of interest are the amount of risk, gain, and no_effect within each trial. 

So we are modeling the probablity of the response from know values our prdictors(log-transformed).

```{r logisitic Regression}
####Logsistic Reg
center_scale <- function(x) {
    scale(x, scale = FALSE)
}

grouped_user_id <- group_by(Neuroethics_Judgement, user_id)
x = mutate(grouped_user_id, risk_c= center_scale(risk))
y = mutate(grouped_user_id, gain_c= center_scale(gain))
foo <- dplyr::select(x, risk_c)
fee <- dplyr::select(y, gain_c)

Neuroethics_Judgement <- cbind.data.frame(Neuroethics_Judgement, foo[,2])
Neuroethics_Judgement <- cbind.data.frame(Neuroethics_Judgement, fee[,2])


subjectModel.1 = by(Neuroethics_Judgement, Neuroethics_Judgement$user_id, function(x) glm(experimental_treatment_selected ~ risk_c + gain_c, data = x, family = binomial(link = "logit"),control=glm.control(maxit=50)))


subjectModel.2 = by(Neuroethics_Judgement, Neuroethics_Judgement$user_id, function(x) glm(experimental_treatment_selected ~ risk_c*gain_c, data = x, family = binomial(link = "logit"),control=glm.control(maxit=50)))

```


```{r Model comparisons}

user_id = names(subjectModel.1) #creates vector of user_id's 
n= nrow(Neuroethics_Judgement)/75

#loop an anove test of the interaction on base and ratio model
datalist = list()
for (i in 1:n){
dat = anova(subjectModel.1[[i]],
            subjectModel.2[[i]],
            test="Chisq")
  datalist[[i]] = dat
}
names(datalist) = user_id

lapply(datalist, print) 
lapply(subjectModel.3, summary)

```

```{r Pseduo R^2s }
source("../r_docs/logisticPseudoR2s.R")

#loop the r^2 calculator on the fitted final model
datalist.1 = list()
for (i in 1:n){
dat = logisticPseudoR2s(subjectModel.2[[i]])
  datalist.1[[i]] = dat
}
#subjectModel.R2 <-  do.call(rbind, datalist.1)
```

```{r odds ratios}
user_id = names(subjectModel.1) #creates vector of user_id's 
n = nrow(Neuroethics_Judgement)/75

#Compute odds ratio
datalist.2 = list()
for (i in 1:n){
dat = exp(subjectModel.2[[i]]$coefficients)
  datalist.2[[i]] = dat
}
subjectModel.OddRatios = do.call(rbind, datalist.2)

colnames(subjectModel.OddRatios) <-  c('Intercept', 'Risk_Beta', 'Gain_Beta', 'Interaction_Beta')

subjectModel.OddRatios <- cbind.data.frame(subjectModel.OddRatios, user_id)

Neuroethics_Judgement= merge(Neuroethics_Judgement, subjectModel.OddRatios, "user_id")
```


```{r pvalue extraction}
user_id = names(subjectModel.2) #creates vector of user_id's 
n= nrow(Neuroethics_Judgement)/75
#we want to pull out the models and give them a logical model signficant or not
datalist.pvalue = list()
for (i in user_id){
dat = coef(summary(subjectModel.2[[i]]))[,4]#This is coef pvalues
  datalist.pvalue[[i]] = dat
}
subjectModel.Pvalue <-t(bind_rows(datalist.pvalue))

colnames(subjectModel.Pvalue) <-  c('Intercept_sig', 'Risk_sig', 'Gain_sig', 'Interaction_sig')

for (ii in 1:4){
  for(jj in 1:n){
    if (subjectModel.Pvalue[jj,ii] > 0.05)
    subjectModel.Pvalue[jj,ii] <- 0
    else 
      subjectModel.Pvalue[jj,ii] <- 1
  }
}

subjectModel.Pvalue <- cbind.data.frame(user_id, subjectModel.Pvalue[,2:4])


Neuroethics_Judgement= merge(Neuroethics_Judgement, subjectModel.Pvalue, "user_id")
```


```{r Model Dignostics for best fitted model}
#Diagnostics for model 2 (Residuals)
#Interpreting residuaLs

datalist.dignostics = list()
for (i in user_id){
subjectDignostics = filter(Neuroethics_Judgement, user_id == i)
  for (ii in 1:n){
    subjectDignostics$predicted.probabilities<-fitted(subjectModel.2[[ii]])
    subjectDignostics$standardized.residuals<-rstandard(subjectModel.2[[ii]])
    subjectDignostics$studentized.residuals<-rstudent(subjectModel.2[[ii]])
    subjectDignostics$dfbeta<-dfbeta(subjectModel.2[[ii]])
    subjectDignostics$dffit<-dffits(subjectModel.2[[ii]])
    subjectDignostics$leverage<-hatvalues(subjectModel.2[[ii]])
  }
    datalist.dignostics[[i]] = subjectDignostics
}

datalist.dignostics = do.call(rbind, datalist.dignostics)

#Neuroethics_Judgement = merge(Neuroethics_Judgement,datalist.dignostics, "user_id")
summary(datalist.dignostics)
```

```{r plot the fitted models for each subject, eval=FALSE, include=FALSE}
#Mutiple Plots
source("../r_docs/Multiple_plot_function.R")

for (i in user_id){
  subject = filter(datalist.dignostics, user_id == i)

  ggplot(subject, aes(x=risk, y= predicted.probabilities)) + 
      stat_summary(fun = mean, geom = "line")+
         scale_x_continuous(expand = c(0,0))
  
  ggplot(subject, aes(x=gain, y= predicted.probabilities)) + 
      stat_summary(fun = mean, geom = "line")+
         scale_x_continuous(expand = c(0,0))
  
    p1 = ggplot(subject, aes(x=risk, y= predicted.probabilities)) + 
         geom_point(size = 4, alpha = .5,   position = "jitter") + 
         stat_smooth(method="glm", se=FALSE, fullrange=TRUE, 
              method.args = list(family=quasibinomial))+
         scale_x_continuous(expand = c(0,0))+
         theme(legend.position="none")

    p2 = ggplot(subject, aes(x=gain, y= predicted.probabilities)) + 
         geom_point(size = 4, alpha = .5, position = "jitter") +
         stat_smooth(method="glm", se=FALSE, fullrange=TRUE, 
              method.args = list(family=quasibinomial))+
         scale_x_continuous(expand = c(0,0))+
         theme(legend.position="none")

    p3 = ggplot(subject,aes(x = risk , y = gain)) + 
         geom_point(aes(color = experimental_treatment_selected), 
                    size = 2.5, alpha = .7, position = "jitter") +
         ggtitle(paste("75 Trials Pilot Subject: ",toString(i))) +
         scale_x_continuous("Risk Probabilities",
                            breaks=seq(0,100,5), limits=c(0, 100)) +
         scale_y_continuous("Gain Probabilities", breaks=seq(0,100,5), 
                            limits=c(0, 100)) + 
         theme(legend.position="none")

     png(filename = paste0(i , ".png"),
       width = 1234, height = 468)
     multiplot(p1, p2, p3, cols=2)
     dev.off()
}

```

```{r loss aversion}

coefficients = lapply(subjectModel.2, coef)
coefficients = do.call(rbind, coefficients)
coefficients = coefficients[,-1]#Removes intercept
#coefficients = coefficients[,3]#Removes interaction
coefficients = data.frame(coefficients)
colnames(coefficients)= c('Risk_Beta', 'Gain_Beta', 'Interaction')
coefficients$user_id = names(subjectModel.2)

coefficients = exp(coefficients)#exponetiated 

Neuroethics_Judgement = mutate(Neuroethics_Judgement, lambda = -Risk_Beta/Gain_Beta)


loss_aversion <- mutate(coefficients, lambda = -Risk_Beta/Gain_Beta)
#loss_aversion = mutate(loss_aversion, risk_aversion = -log(Risk_Beta))

ggplot(loss_aversion, aes(x=lambda)) +
    geom_histogram(binwidth=1, colour="black", fill="white") +
    geom_vline(aes(xintercept=mean(lambda, na.rm=T)),
               color="red", linetype="dashed", size=1)+
    scale_x_continuous("Lambda", breaks=seq(-20,20,1), limits=c(-20, 20))+
    scale_y_continuous("Number of Occurrences")

kable((summary(loss_aversion[5])), caption = "summary of lambda calculation")


# A basic box with the conditions colored
dat <- melt(coefficients, 
                       id = c("user_id"),
                       variable.name = "cond", 
                       value.name = "Beta")

ggplot(dat, aes(x=cond, y=Beta, fill=cond)) + geom_boxplot()+
      scale_y_continuous(limits=c(-.5, .5))

```

##H2

Participants risk aversion to harm will change as the cognitive domain being treated changes. Specifically, participants will be more risk averse to mood, and self-control because these are more central to self-identity.

```{r drafts, eval=FALSE, include=FALSE, fig.height=7, fig.width=12, dpi=300}
dat.1 = distinct(select(Neuroethics_Judgement, user_id , condition ,  Risk_Beta , Gain_Beta , Interaction_Beta, sex, age_4, education))

dat.2 = distinct(select(Neuroethics_Judgement, user_id , condition, sex, age_4, education, Risk_sig, Gain_sig, Interaction_sig))

dat$user_id <- as.factor(dat$user_id)
dat$education <- as.factor(dat$education)


data_long.1 = melt(dat.1, 
            id = c("user_id", "condition", "sex", "education", "age_4"),
                       variable.name = "type", 
                       value.name = "Stimulus")

data_long.2 = melt(dat.2, 
            id = c("user_id", "condition", "sex", "education", "age_4"),
                       variable.name = "type", 
                       value.name = "Stimulus")

#Significant plots
ggplot(data_long.2, aes(x = type, fill = as.factor(Stimulus))) +
         geom_bar(color = 'black', stat="count", position = "dodge")+
         theme_classic()


center_scale <- function(x) {
    scale(x, scale = FALSE)
}

data_long$age_4 <- center_scale(data_long$age_4)

m <- aov(Interaction_Beta ~ age_4 +sex + education + condition , data = dat)

summary(m)
model.tables(aov, "means")
TukeyHSD(aov)
```


```{r manuscript plot drafts, eval=FALSE, include=FALSE}
#Draft of Main Box Plot Across conditions


ggplot(data_long, aes(condition, y=value, fill=variable)) +
  geom_boxplot()+
  scale_y_continuous("Beta", breaks=seq(-1, 2,.5), limits=c(-1, 2)) +
  theme(axis.text.x = element_text(angle=65, vjust=0.6)) +
  labs(title="", 
       subtitle="an investigation of domain differences",
       x="Cognitive Domian",
       y="Log Odds")

#Separate Box Plots across conditions
ggplot(data_long, aes(condition, y=value, fill=variable)) +
  geom_boxplot()+
  facet_wrap(~condition, scale="free")
```

##Testing stuff

```{r Density plots of beta per cog domain, eval=FALSE, include=FALSE}
#Density Plot for Risk, Gain,  Ratio
p1 = ggplot(TEST, aes(Risk_Beta)) +
  geom_density(aes(fill=factor(condition)), alpha=0.8) +
  scale_x_continuous("Beta", breaks=seq(-5,10,1), limits=c(-5, 10))+
  theme(axis.text.x = element_text(angle=65, vjust=0.6))


p2 = ggplot(TEST, aes(Gain_Beta)) +
  geom_density(aes(fill=factor(condition)), alpha=0.8) +
  scale_x_continuous("Beta", breaks=seq(-5,10,1), limits=c(-5, 10))+
  theme(axis.text.x = element_text(angle=65, vjust=0.6))
```

```{r mixed effect models drafts}
library(reshape2)
library(lme4)
library(lmerTest)
feee <- Neuroethics_Judgement

multilevel.data <- dplyr::select(feee, user_id , condition ,  risk , gain, experimental_treatment_selected, trial_index)

multilevel.data$user_id <- as.factor(multilevel.data$user_id)
multilevel.data$trial_index <- as.numeric(multilevel.data$trial_index)

multilevel.data = melt(multilevel.data, 
                       id = c("user_id", "experimental_treatment_selected", "condition", "trial_index"),
                       variable.name = "type", 
                       value.name = "Stimulus")



mlm$trial_index <- as.numeric(mlm$trial_index)
mlm$user_id <- as.factor(mlm$user_id)
mlm$experimental_treatment_selected <- as.numeric(mlm$experimental_treatment_selected)

m.base <- glmer(experimental_treatment_selected ~ trial_index + 
                  (risk_c + gain_c | user_id),
               data = mlm, family = binomial)
m.1 <- glmer(experimental_treatment_selected ~ trial_index + risk_c + 
               (risk_c + gain_c| user_id),
               data = mlm, family = binomial)

m.2 <- glmer(experimental_treatment_selected ~ trial_index + risk_c + gain_c +
               (risk_c + gain_c| user_id),
               data = mlm, family = binomial)

m.3 <-  glmer(experimental_treatment_selected ~ trial_index + risk_c + gain_c + condition +
                (risk_c + gain_c | user_id),
              control = glmerControl(optimizer = "bobyqa"),
               data = mlm, family = binomial)


anova(m.base,m.1,m.2,m.3)

summary(m.2)


t <- poly(mlm$risk, 3)

mlm[, paste("ot", 1:3, sep="")] <- 
  t[mlm$risk, 1:3]



m.base <- glmer(experimental_treatment_selected ~ (ot1+ ot2 +ot3) + 
                  (1 + ot1 + ot2 +ot3  | user_id),
                control = glmerControl(optimizer = "bobyqa"),
               data = mlm, family = binomial)

m.1 <- glmer(experimental_treatment_selected ~ (ot1+ ot2 +ot3) + condition + 
                  (1 + ot1 + ot2 +ot3  | user_id),
                control = glmerControl(optimizer = "bobyqa"),
               data = mlm, family = binomial)

m.2 <- glmer(experimental_treatment_selected ~ trial_index + (ot1+ ot2 +ot3) +
                  (1 + ot1 + ot2 +ot3  + trial_index| user_id),
                control = glmerControl(optimizer = "bobyqa"),
               data = mlm, family = binomial)


p1 <- ggplot(mlm, aes(risk, experimental_treatment_selected, color = condition)) +
stat_summary(fun.data=mean_se) +
stat_summary(aes(y=fitted(m.2)), fun=mean, geom="line")+
labs(x= "proabalitiy risk of harm", y= "outcome") +
ggtitle("Figure 1")+theme(legend.position="none") +
  scale_x_continuous("risk", breaks=seq(0, 100, 5))


p2 <- ggplot(mlm, aes(gain, experimental_treatment_selected, color = condition)) +
stat_summary(fun.data=mean_se) +
stat_summary(aes(y=fitted(m.2)), fun=mean, geom="line")+
labs(x= "proabalitiy benifit from gain", y= "outcome") +
ggtitle("Figure 2")+theme(legend.position="none")+
    scale_x_continuous("gain", breaks=seq(0, 100, 5))


library(gridExtra)

grid.arrange(p1,p2,ncol=2)
```

```{r Testing multicollinearity, eval=FALSE, include=FALSE}
library(car)

vif(subjectModel.2)
1/vif(subjectModel.2)

cor(subject[, c("risk", "gain", "no_effect")])

cor.test(subject$risk, subject$gain)  
cor.test(subject$risk, subject$no_effect)  
cor.test(subject$gain, subject$no_effect)
```

```{r Testing the linearity of the logit, eval=FALSE, include=FALSE}

#Create the interaction of Risk with log(risk)
subject$logRisk<-log(subject$risk)*subject$risk

#Create the interaction of Gain and No Effect with their logs

subject$logGain<-log(subject$gain)*subject$gain
subject$logNo_effect<-log(subject$no_effect)*subject$no_effect

head(subject)



subjectTest.1 <- glm(experimental_treatment_selected ~ 
                       risk +
                       gain + 
                       no_effect +
                       logRisk +
                       logGain +	
                       logNo_effect, 
                     data=subject, family=binomial())
summary(subjectTest.1)
# None of the Interaction variables show significance, so linearity test passes
```

```{r users to remove}
REMOVE = c(
  "wpchz8fz",
  "tdDTyNLl",
  "CUyB01Th",
  "d9UbV0sj",
  "PiGCo5DO",
  "yCZDIVJF",
  "WUTFOue2",
  "Rp8H93tM",
  "9Z5vJ7oT",
  "esSkjqdS",
  "XNHqndg3",
  "spGR9XvT",
  "qf27dbHj",
  "y6m1AOsD",
  "hgbHHiLn",
  "Ly8mJkxP"
)

Neuroethics_Judgement %>%
      group_by(user_id)  %>%
      mutate(Neuroethics_Judgement, risk_c= risk-mean(risk)) %>%
      mutate(Neuroethics_Judgement, gain_c= gain-mean(gain))

Neuroethics_Judgement %>%
      group_by(user_id)  %>%
      mutate(risk_c= risk-mean(risk)) %>%
      mutate(gain_c= gain-mean(gain))
```

```{r odds ratio confidence intervals, eval=FALSE, include=FALSE}
#Compute odds ratio confidence interval
#only works if values do not contain infinites...
datalist.3 = list()
for (i in 1:n){
dat = exp(confint(subjectModel.2[[i]]))
  datalist.3[[i]] = dat
}
```

```{r}

for (i in user_id){
  subject = filter(datalist.dignostics, user_id == i)

 p1 <-  ggplot(subject, aes(x=risk, y= standardized.residuals)) + 
          geom_point(position = 'jitter')+
          stat_smooth(method="glm", se=FALSE, fullrange=TRUE, 
              method.args = list(family=quasibinomial))+
          scale_x_continuous(expand = c(0,0))+
          scale_y_continuous("Mean Responce (0 = No 1 = Yes)",breaks=seq(0,1,0.25), 
                            limits=c(0, 1))
  
  p2 <- ggplot(subject, aes(x=gain, y= predicted.probabilities)) + 
           stat_summary(fun = mean, geom = "line")+
          
           scale_x_continuous(expand = c(0,0))+
          scale_y_continuous("Mean Responce (0 = No 1 = Yes)",breaks=seq(0,1,0.25), 
                            limits=c(0, 1))  
   png(filename = paste0(i , ".png"),
       width = 1234, height = 468)
     multiplot(p1, p2, cols=2)
     dev.off()
}
```